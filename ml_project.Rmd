---
title: "MachineLearning"
author: "Siddharth Hatkar"
date: "11/18/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r, echo=TRUE}
#install.packages("dataPreparation")
#install.packages("corrplot")
library("dataPreparation")
library("mlbench")
library("e1071")
library("caret")
library("ROCR")
library("kernlab")
library("corrplot")
library("caret")

OJ <- read.csv(url("http://data.mishra.us/files/OJ.csv"))

```

## Removing irrelevant variables

You can also embed plots, for example:
```{r, echo=TRUE}
constant_cols <- whichAreConstant(OJ)
double_cols <- whichAreInDouble(OJ)
bijections_cols <- whichAreBijection(OJ)

```
```{r, echo=TRUE}
#Store 7 and Store are redundant variables. These two varaibles provide same information as the StoreID variable. When the store is 7, at that time, StoreID will be 7 and Store7 will be yes, also the value of store will be zero and when store is some other value, say 1, StoreID will be 1, Store7 will be No, and Store will be 1. Therefore, we can only keep StoreID and through this we can derive other information.
#STORE is a bijection of STOREID

#Similarly, we can also remove the ListPriceDiff and PriceDiff. These two can also be derived from the other variables. PriceDiff can be derived by subtracting SalePriceCH from SalePriceMM and similarly, ListPriceDiff can be derived by subtracting PriceCH from PriceMM.

#Bool_OJ <- names(OJ) %in% c("Store7","STORE", "PriceDiff", "ListPriceDiff")
#New_OJ <- OJ[!Bool_OJ]

New_OJ <- OJ[, c(-18)]
included_cols <- whichAreIncluded(New_OJ)

```

```{r, echo=TRUE}
#Finding the attributes which need to be factored
New_OJ <- New_OJ[, c(-6,-7,-14)]
str(New_OJ)

#factorizing the required attributes
New_OJ$StoreID <- as.factor(New_OJ$StoreID)
New_OJ$Purchase <- ifelse(New_OJ$Purchase == "CH", 1, 0)

str(New_OJ)

```

```{r, echo=TRUE}

# Correlation 
Cor_data <- New_OJ[, c("PriceCH", "PriceMM", "LoyalCH", "SalePriceMM", "SalePriceCH", "PriceDiff", "PctDiscMM", "PctDiscCH", "ListPriceDiff")]
cor_result <- cor(Cor_data)
cor_result
corrplot(cor_result, method="number")
```
```{r, echo=TRUE}
#Removing attributes having high correlation
#SalePriceCH
#SalePriceMM
#PriceDiff
#ListPriceDiff

New_OJ <- New_OJ[, c(-9, -10, -11, -14)]
```

```{r, echo=TRUE}
#LOGISTIC REGRESSION

split = 0.8
set.seed(99894)

train_index <- sample(1:nrow(New_OJ), split * nrow(New_OJ))
test_index <- setdiff(1:nrow(New_OJ), train_index)

OJ_train <- New_OJ[train_index,]
OJ_test <- New_OJ[test_index,]

glm1 <- glm(family = "binomial", Purchase ~., data = OJ_train)

prediction <- predict(glm1, OJ_test, type = "response")
result <- ifelse(prediction > 0.50, 1, 0)

conf <- table(result, OJ_test$Purchase)
conf
accuracy <- (conf[1] + conf[4])/(sum(conf))
accuracy

```

```{r, echo=TRUE}
#SVM

New_OJ2 <- OJ %>% 
mutate(Purchase = recode_factor(Purchase, "MM" = 'Y' , "CH" = 'N'),
       StoreID = factor(StoreID),
       SpecialCH = factor(SpecialCH),
       SpecialMM = factor(SpecialMM),
       Purchase = factor(Purchase),
       )


# IDENTIFYING VARIABLES THAT ARE EITHER CONSTANTS, DOUBLES or BIJECTIONS
b_vars <- whichAreBijection(New_OJ2)
c_vars <- whichAreConstant(New_OJ2)
d_vars <- whichAreInDouble(New_OJ2)
b_vars
c_vars
d_vars



# REMOVING VARIABLES

New_OJ2 <- New_OJ2[,c(-18)]

# Removing Included Variables
i_vars <- whichAreIncluded(New_OJ2)
i_vars
New_OJ2 <- New_OJ2[,c(-14,-7,-6)]

#Finding Correlation Matrix using numrical attributes
cor_data <- New_OJ2[, c(-1,-2,-3,-6,-7)]
corr_mat <- cor(cor_data)
corrplot(corr_mat, method = "number")

#Removing the highly correlated attributes

New_OJ2 <- New_OJ2[,c(-14,-11,-10,-9)]

#Model1 & Model2

New_OJ2 <- New_OJ2[,c(-2)]

#Code from SVM class

X_train_unscaled <- New_OJ2[train_index,-1]
y_train <- New_OJ2[train_index, 1]

X_test_unscaled <- New_OJ2[test_index, -1]
y_test <- New_OJ2[test_index, 1]


# DATA IS STANDARDIZED AND ENCODED (see see https://cran.r-project.org/web/packages/dataPreparation/vignettes/train_test_prep.html)
# Standardize continuous variables...
scales <- build_scales(dataSet = X_train_unscaled, cols = "auto", verbose = FALSE) 

X_train <- fastScale(dataSet = X_train_unscaled, scales = scales, verbose = FALSE)
X_test <- fastScale(dataSet = X_test_unscaled, scales = scales, verbose = FALSE)

# Encode categorical variables...
encoding <- build_encoding(dataSet = X_train, cols = "auto", verbose = FALSE) 
X_train <- one_hot_encoder(dataSet = X_train, encoding = encoding, drop = TRUE, verbose = FALSE)
X_test <- one_hot_encoder(dataSet = X_test, encoding = encoding, drop = TRUE, verbose = FALSE)

# Create one data frame using both Outcome and Predictor Variables

train_Data <- cbind(y_train,X_train)
```


```{r, echo=TRUE}

fitControl <- trainControl(## 4-fold CV
  method = "repeatedcv",
  number = 4,
  ## repeated two times
  repeats = 2,
  summaryFunction=twoClassSummary,
  classProbs = TRUE)

grid <- expand.grid(sigma = c(.01,.05),
                    C = c(.05,.75,1,1.5,2))

# FIND OPTIMAL TUNING PARAMETERS (C and SIGMA)

svmFit1 <- train(Purchase ~ ., data = train_Data, 
                 method='svmRadial',  
                 trControl = fitControl,
                 metric = "ROC",
                 verbose = FALSE,
                 probability = TRUE,
                 tuneGrid = grid
                 
)
#final values of hyperparameters; sigma = 0.01, C = 2

##Create a plot of ROC with with different values of C and gamma


svmFit1
plot(svmFit1)

## Predict
svmPred <- predict(svmFit1, newdata = X_test, probability = TRUE)

confusionMatrix(data = svmPred, as.factor(y_test$Purchase))
```


```{r, echo=TRUE}
#LinearSVM 
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
svmFitL <- train(Purchase ~ ., data = train_Data, 
                 method='svmLinear',  
                 trControl = trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 10)
                 


svmFitL

## Predict
svmPredL <- predict(svmFitL, newdata = X_test, probability = TRUE)

confusionMatrix(data = svmPredL, as.factor(y_test$Purchase))
```

